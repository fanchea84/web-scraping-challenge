{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News: \n",
    "#### Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step opens a new chrome window that will be driven by code in the next few cells\n",
    "# It also adds another Chrome icon on the taskbar because it's using chromedriver instead of chrome\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step navigates the chromebrowser window to NASA News site & runs BeautifulSoup to parse the site's HTML\n",
    "nasa_url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(nasa_url)\n",
    "sleep(3) # This is a manual delay that prevents a \"Race Condition\" with JavaScript and this script competing for resources\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA Moves Forward With Campaign to Return Mars Samples to Earth'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the latest headline from NASA Mars News\n",
    "nasa_headline = soup.find_all(\"div\", class_=\"content_title\")[1].get_text()\n",
    "nasa_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During this next phase, the program will mature critical technologies and make critical design decisions as well as assess industry partnerships.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the latest teaser from NASA Mars News\n",
    "nasa_teaser = soup.find_all(\"div\", class_=\"article_teaser_body\")[0].get_text()\n",
    "nasa_teaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the chromebrowser window\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADAM: this code is \"test code\" from Dec 11th tutoring. Probably ok to delete this before submitting final homework.\n",
    "# sidebar = soup.find('div', class_='content_title')\n",
    "# categories = sidebar.find_all('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images\n",
    "#### Use splinter to find the current Featured Mars Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step opens a new chrome window that will be driven by code in the next few cells\n",
    "# It also adds another Chrome icon on the taskbar because it's using chromedriver instead of chrome\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step navigates the chromebrowser window to JPL images site & runs BeautifulSoup to parse the site's HTML\n",
    "jpl_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(jpl_url)\n",
    "sleep(3) # This is a manual delay that prevents a \"Race Condition\" with JavaScript and this script competing for resources\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step clicks on the FULL IMAGE link (in the chromebrowser window)\n",
    "browser.click_link_by_partial_text(\"FULL IMAGE\")\n",
    "# browser.links.find_by_partial_text(\"FULL IMAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step clicks on the MORE INFO link (in the chromebrowser window)\n",
    "sleep(3) # This is a manual delay that prevents a \"Race Condition\" with JavaScript and this script competing for resources\n",
    "browser.click_link_by_partial_text(\"more info\")\n",
    "# browser.links.find_by_partial_text(\"more info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step clicks on the JPEG image (in the chromebrowser window)\n",
    "browser.click_link_by_partial_text(\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step saves as a variable the URL of the JPEG image file \n",
    "featured_image_url = browser.url\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the chromebrowser window\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "#### Use Pandas to scrape the Mars Data table containing facts about the planet including Diameter, Mass, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define URL of Mars Facts website\n",
    "facts_url = \"https://space-facts.com/mars/\"\n",
    "#  Read in data table via Pandas. \n",
    "# Specify zero'th position to get just Mars data, since table contains both Mars & Earth data \n",
    "facts_df = pd.read_html(facts_url)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"pretty\" Mars Facts dataframe with column headers and text clean-up\n",
    "facts_df.columns = [\"Metric\", \"Value (Planet Mars)\"]\n",
    "facts_df[\"Metric\"] = facts_df[\"Metric\"].str.replace(\":\",\"\") # Remove the colon character in DESCRIPTION column\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to convert the data to a HTML table string\n",
    "facts_df.set_index(\"Metric\", inplace=True)\n",
    "facts_html = facts_df.to_html()\n",
    "# print(facts_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "#### Scrape from USGS Astrogeology site hi-res images for each of Mars' hemispheres, including URL for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step opens a new chrome window that will be driven by code in the next few cells\n",
    "# It also adds another Chrome icon on the taskbar because it's using chromedriver instead of chrome\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step navigates the chromebrowser window to USGS Astrogeology & runs BeautifulSoup to parse the site's HTML\n",
    "mars_hemisphere_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(mars_hemisphere_url)\n",
    "sleep(3) # This is a manual delay that prevents a \"Race Condition\" with JavaScript and this script competing for resources\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of Mars Hemisphere names, empty list for housing hemisphere image URLs, \n",
    "# and empty dictionary for housing hemisphere names & image URLS\n",
    "mars_hemispheres = [\"Cerberus\",\"Schiaparelli\",\"Syrtis\",\"Valles\"]\n",
    "hemisphere_pic_urls = []\n",
    "hemi_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through list of hemispheres, and populate dictionary with name & image URL by scraping USGS site\n",
    "for hemi in mars_hemispheres:\n",
    "    browser.click_link_by_partial_text(hemi)\n",
    "    hemi_html = browser.html\n",
    "    soup = BeautifulSoup(hemi_html, 'html.parser')\n",
    "    hemi_dict[\"title\"] = soup.find(\"h2\").get_text().replace(\"Enhanced\",\"\").strip()\n",
    "    hemi_dict[\"img_url\"] = soup.find_all(\"div\", class_=\"downloads\")[0].find_all(\"a\")[0][\"href\"]\n",
    "    hemisphere_pic_urls.append(hemi_dict)\n",
    "    browser.back() # go back to original page with all the hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dictionary containing Mars hemisphere names & images\n",
    "hemisphere_pic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the chromebrowser window\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
